{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000999ab-7ab7-4511-905e-8e2a1d3f5341",
   "metadata": {},
   "source": [
    "# Creating SQL data base using SQLLit\n",
    "\n",
    "Simple Data warehousing done with SQLlit. It's not typically used for large-scale data warehousing like Snowflake, but it can be useful for small to medium-sized datasets, prototyping, or educational purposes, because  SQLite's nature as a lightweight, file-based database system.\n",
    "\n",
    "### Step1 : Importing necessary library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b3f03f-1ec3-4b1e-bcd4-c113d965536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67c945-d250-4ac6-8480-e6af3e130759",
   "metadata": {},
   "source": [
    "### Step 2: Creating the 3 sample Dim tables and 1 Fact table to create star schema \n",
    "\n",
    "-Dim table 1 --> date table <br>\n",
    "-Dim table 2 --> Product table<br>\n",
    "-Dim table 3 --> Store table\n",
    "\n",
    "-Fact table -->Sales_fact table\n",
    "\n",
    " IF NOt fuction is used to check the table already created.\n",
    "\n",
    "Fcat table is the main table hold infromation about all the dim table. <br>\n",
    "(Note: It's basic table formation can be modified based no needs by adding extra tables, assignee respective data types and filed names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998da93a-fbfd-4643-b57f-5a548f3e8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS date_dim (\n",
    "        date_id INTEGER PRIMARY KEY,\n",
    "        date TEXT,\n",
    "        month TEXT,\n",
    "        quarter TEXT,\n",
    "        year INTEGER\n",
    "    );\n",
    "    \"\"\")\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS product_dim (\n",
    "        product_id INTEGER PRIMARY KEY,\n",
    "        product_name TEXT,\n",
    "        category TEXT,\n",
    "        price REAL\n",
    "    );\n",
    "    \"\"\")\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS store_dim (\n",
    "        store_id INTEGER PRIMARY KEY,\n",
    "        store_name TEXT,\n",
    "        location TEXT,\n",
    "        manager TEXT\n",
    "    );\n",
    "    \"\"\")\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS sales_fact (\n",
    "        sales_id INTEGER PRIMARY KEY,\n",
    "        date_id INTEGER,\n",
    "        product_id INTEGER,\n",
    "        store_id INTEGER,\n",
    "        quantity_sold INTEGER,\n",
    "        sales_amount REAL,\n",
    "        FOREIGN KEY (date_id) REFERENCES date_dim(date_id),\n",
    "        FOREIGN KEY (product_id) REFERENCES product_dim(product_id),\n",
    "        FOREIGN KEY (store_id) REFERENCES store_dim(store_id)\n",
    "    );\n",
    "    \"\"\")\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86a2dd-12ee-4275-ae43-285cc15cbf77",
   "metadata": {},
   "source": [
    "### Step 3:  Data Ingestion <br>\n",
    "\n",
    "Here we can ingest the data into table from any source by creating the connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2864ccaf-f095-495b-98a3-83745004c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_tables(conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.executemany(\"\"\"\n",
    "    INSERT OR IGNORE INTO date_dim (date_id, date, month, quarter, year) VALUES ;\n",
    "    \"\"\", [\n",
    "        (1, '2024-01-01', 'January', 'Q1', 2024),\n",
    "        (2, '2024-01-02', 'January', 'Q1', 2024)\n",
    "    ])\n",
    "    cursor.executemany(\"\"\"\n",
    "    INSERT OR IGNORE INTO product_dim (product_id, product_name, category, price) VALUES ;\n",
    "    \"\"\", [\n",
    "        (1, 'Laptop', 'Electronics', 1200.00),\n",
    "        (2, 'Smartphone', 'Electronics', 800.00)\n",
    "    ])\n",
    "    cursor.executemany(\"\"\"\n",
    "    INSERT OR IGNORE INTO store_dim (store_id, store_name, location, manager) VALUES ;\n",
    "    \"\"\", [\n",
    "        (1, 'Store A', 'New York', 'John Doe'),\n",
    "        (2, 'Store B', 'San Francisco', 'Jane Smith')\n",
    "    ])\n",
    "    cursor.executemany(\"\"\"\n",
    "    INSERT OR IGNORE INTO sales_fact (sales_id, date_id, product_id, store_id, quantity_sold, sales_amount) VALUES ;\n",
    "    \"\"\", [\n",
    "        (1, 1, 1, 1, 2, 2400.00),\n",
    "        (2, 2, 2, 2, 1, 800.00)\n",
    "    ])\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f79ee-ff44-4616-8240-aab6b89a4c0e",
   "metadata": {},
   "source": [
    "### Step4: Establishing the connection between the fact and Dim table to create star schema using SQL joint \n",
    "\n",
    "The results were established with pandas df. <br>\n",
    "(Note: Even Snowflake schema can be create by creating more sub dim table )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5129cf7-813f-45bc-85cf-68e2b2f498b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_star_schema(conn):\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        d.date,\n",
    "        p.product_name,\n",
    "        s.store_name,\n",
    "        f.quantity_sold,\n",
    "        f.sales_amount\n",
    "    FROM \n",
    "        sales_fact f\n",
    "    JOIN \n",
    "        date_dim d ON f.date_id = d.date_id\n",
    "    JOIN \n",
    "        product_dim p ON f.product_id = p.product_id\n",
    "    JOIN \n",
    "        store_dim s ON f.store_id = s.store_id\n",
    "    WHERE \n",
    "        d.year = 2024;\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3abd5-5296-4a86-b25f-7f388e612455",
   "metadata": {},
   "source": [
    "### Once Query executed close the connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "85d94fe9-f5c0-49dc-ab50-cc61d06cf0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date product_name store_name  quantity_sold  sales_amount\n",
      "0  2024-01-01       Laptop    Store A              2        2400.0\n",
      "1  2024-01-02   Smartphone    Store B              1         800.0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Path to your existing SQLite database file\n",
    "    db_path = 'retail_sales.db'\n",
    "    \n",
    "    # Connect to the existing database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Query the star schema and get the results in a DataFrame\n",
    "    df = query_star_schema(conn)\n",
    "    \n",
    "    # Print the results\n",
    "    print(df)\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc575a1-702d-4298-b2c5-2b1ae39a990e",
   "metadata": {},
   "source": [
    "### New Query can be create with the existing database by establishing the new connection \n",
    "\n",
    "Below 4 new Query samples were executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0130ed22-0c64-4d03-9bfb-4320816222e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1 Results:\n",
      "         date product_name store_name  quantity_sold  sales_amount\n",
      "0  2024-01-01       Laptop    Store A              2        2400.0\n",
      "1  2024-01-02   Smartphone    Store B              1         800.0\n",
      "\n",
      "Query 2 Results:\n",
      "  product_name  total_sales\n",
      "0       Laptop       2400.0\n",
      "1   Smartphone        800.0\n",
      "\n",
      "Query 3 Results:\n",
      "  store_name  total_quantity\n",
      "0    Store A               2\n",
      "1    Store B               1\n",
      "\n",
      "Query 4 Results:\n",
      "     month  total_sales\n",
      "0  January       3200.0\n"
     ]
    }
   ],
   "source": [
    "def establish_connection(db_path):\n",
    "    \"\"\"Establish a connection to the SQLite database.\"\"\"\n",
    "    return sqlite3.connect(db_path)\n",
    "\n",
    "def execute_query(conn, query):\n",
    "    \"\"\"Execute a given SQL query and return the results as a DataFrame.\"\"\"\n",
    "    return pd.read_sql_query(query, conn)\n",
    "\n",
    "def run_queries(db_path):\n",
    "    \"\"\"Run multiple queries on the database and print the results.\"\"\"\n",
    "    # Establish connection\n",
    "    conn = establish_connection(db_path)\n",
    "    \n",
    "    # Example query 1: Join all tables and retrieve sales data for the year 2024\n",
    "    query1 = \"\"\"\n",
    "    SELECT \n",
    "        d.date,\n",
    "        p.product_name,\n",
    "        s.store_name,\n",
    "        f.quantity_sold,\n",
    "        f.sales_amount\n",
    "    FROM \n",
    "        sales_fact f\n",
    "    JOIN \n",
    "        date_dim d ON f.date_id = d.date_id\n",
    "    JOIN \n",
    "        product_dim p ON f.product_id = p.product_id\n",
    "    JOIN \n",
    "        store_dim s ON f.store_id = s.store_id\n",
    "    WHERE \n",
    "        d.year = 2024;\n",
    "    \"\"\"\n",
    "    df1 = execute_query(conn, query1)\n",
    "    print(\"\\nQuery 1 Results:\")\n",
    "    print(df1)\n",
    "    \n",
    "    # Example query 2: Total sales amount by product\n",
    "    query2 = \"\"\"\n",
    "    SELECT \n",
    "        p.product_name,\n",
    "        SUM(f.sales_amount) AS total_sales\n",
    "    FROM \n",
    "        sales_fact f\n",
    "    JOIN \n",
    "        product_dim p ON f.product_id = p.product_id\n",
    "    GROUP BY \n",
    "        p.product_name;\n",
    "    \"\"\"\n",
    "    df2 = execute_query(conn, query2)\n",
    "    print(\"\\nQuery 2 Results:\")\n",
    "    print(df2)\n",
    "    \n",
    "    # Example query 3: Total quantity sold by store\n",
    "    query3 = \"\"\"\n",
    "    SELECT \n",
    "        s.store_name,\n",
    "        SUM(f.quantity_sold) AS total_quantity\n",
    "    FROM \n",
    "        sales_fact f\n",
    "    JOIN \n",
    "        store_dim s ON f.store_id = s.store_id\n",
    "    GROUP BY \n",
    "        s.store_name;\n",
    "    \"\"\"\n",
    "    df3 = execute_query(conn, query3)\n",
    "    print(\"\\nQuery 3 Results:\")\n",
    "    print(df3)\n",
    "    \n",
    "    # Example query 4: Monthly sales\n",
    "    query4 = \"\"\"\n",
    "    SELECT \n",
    "        d.month,\n",
    "        SUM(f.sales_amount) AS total_sales\n",
    "    FROM \n",
    "        sales_fact f\n",
    "    JOIN \n",
    "        date_dim d ON f.date_id = d.date_id\n",
    "    GROUP BY \n",
    "        d.month;\n",
    "    \"\"\"\n",
    "    df4 = execute_query(conn, query4)\n",
    "    print(\"\\nQuery 4 Results:\")\n",
    "    print(df4)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "# Path to your existing SQLite database file\n",
    "db_path = 'retail_sales.db'\n",
    "\n",
    "# Run the queries\n",
    "run_queries(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bc4ef-dcf7-4d9d-b5ea-d1e71945d587",
   "metadata": {},
   "source": [
    "## one more query so we can do how many query performance we needed \n",
    "(Note: Each time once request done close the connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fde4f22f-b449-47a4-813d-92dfb634ca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 5 Results: Sales by Quarter\n",
      "  quarter  total_sales\n",
      "0      Q1       3200.0\n"
     ]
    }
   ],
   "source": [
    "def run_new_query(db_path):\n",
    "    \"\"\"Run a new query on the database and print the results.\"\"\"\n",
    "    # Establish connection\n",
    "    conn = establish_connection(db_path)\n",
    "    \n",
    "    # New query example: Sales by quarter\n",
    "    query5 = \"\"\"\n",
    "    SELECT \n",
    "        d.quarter,\n",
    "        SUM(f.sales_amount) AS total_sales\n",
    "    FROM \n",
    "        sales_fact f\n",
    "    JOIN \n",
    "        date_dim d ON f.date_id = d.date_id\n",
    "    GROUP BY \n",
    "        d.quarter;\n",
    "    \"\"\"\n",
    "    df5 = execute_query(conn, query5)\n",
    "    print(\"Query 5 Results: Sales by Quarter\")\n",
    "    print(df5)\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "# Run the new query\n",
    "run_new_query(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33657d31-cf1c-483d-9c89-392010d1e7df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
